import os
import argparse
import torch
from diffusers import AutoencoderKL, UNet2DModel, DDPMScheduler
from torchvision.utils import save_image
from tqdm import tqdm

def generate_masks(args):
    device = torch.device(f"cuda:{args.gpu}" if torch.cuda.is_available() else "cpu")
    os.makedirs(args.output_dir, exist_ok=True)

    print(f"ğŸš€ Custom LDM ì¶”ë¡  ì‹œì‘")
    print(f" - VAE ê²½ë¡œ: {args.vae_path}")
    print(f" - UNet ê²½ë¡œ: {args.unet_path}")
    print(f" - Scaling Factor: {args.scale_factor}")

    # 1. ëª¨ë¸ ë¡œë“œ
    # 1-1. VAE (ì§ì ‘ í•™ìŠµí•œ ëª¨ë¸)
    try:
        vae = AutoencoderKL.from_pretrained(args.vae_path).to(device)
    except:
        print("âŒ ì˜¤ë¥˜: VAE ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    # 1-2. UNet (LDM í•™ìŠµ ê²°ê³¼)
    unet = UNet2DModel.from_pretrained(args.unet_path).to(device)
    
    # 1-3. ìŠ¤ì¼€ì¤„ëŸ¬ (í•™ìŠµ ë•Œì™€ ë™ì¼í•œ ì„¤ì •)
    scheduler = DDPMScheduler(num_train_timesteps=1000)

    unet.eval()
    vae.eval()

    # 2. ìƒì„± ë£¨í”„
    # Latent Channel ìˆ˜ëŠ” VAE ì„¤ì •ì—ì„œ ê°€ì ¸ì˜´ (ë³´í†µ 4)
    latent_channels = vae.config.latent_channels
    
    # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ìƒì„±
    num_batches = (args.num_samples + args.batch_size - 1) // args.batch_size
    
    for i in range(num_batches):
        # í˜„ì¬ ë°°ì¹˜ì˜ í¬ê¸° ê³„ì‚° (ë§ˆì§€ë§‰ ë°°ì¹˜ëŠ” ì‘ì„ ìˆ˜ ìˆìŒ)
        curr_batch_size = min(args.batch_size, args.num_samples - i * args.batch_size)
        
        # A. ëœë¤ ë…¸ì´ì¦ˆ ìƒì„± (Latent Space)
        # 512x512 -> 64x64 (f=8)
        latents = torch.randn(
            (curr_batch_size, latent_channels, args.resolution // 8, args.resolution // 8),
            device=device
        )

        # B. Denoising Process (Reverse Diffusion)
        for t in tqdm(scheduler.timesteps, desc=f"Generating Batch {i+1}/{num_batches}"):
            with torch.no_grad():
                # ë…¸ì´ì¦ˆ ì˜ˆì¸¡
                noise_pred = unet(latents, t).sample
                # ë…¸ì´ì¦ˆ ì œê±° (Step)
                latents = scheduler.step(noise_pred, t, latents).prev_sample

        # C. VAE Decoding
        # Scaling Factorë¡œ ë‚˜ëˆ„ì–´ì¤˜ì•¼ ì›ë˜ ìŠ¤ì¼€ì¼ë¡œ ëŒì•„ì˜´
        latents = latents / args.scale_factor
        
        with torch.no_grad():
            images = vae.decode(latents).sample

        # D. ì €ì¥ ([-1, 1] -> [0, 1])
        images = (images / 2 + 0.5).clamp(0, 1)
        
        for j, img in enumerate(images):
            idx = i * args.batch_size + j
            save_path = os.path.join(args.output_dir, f"generated_{idx:04d}.png")
            save_image(img, save_path)

    print(f"ğŸ‰ ìƒì„± ì™„ë£Œ! ì €ì¥ ìœ„ì¹˜: {args.output_dir}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--unet_path", type=str, required=True, help="í•™ìŠµëœ UNet í´ë” (ì˜ˆ: ldm_result/best_unet)")
    parser.add_argument("--vae_path", type=str, required=True, help="í•™ìŠµëœ VAE í´ë” (ì˜ˆ: vae_result/best_vae)")
    parser.add_argument("--output_dir", type=str, default="generated_samples_custom")
    parser.add_argument("--num_samples", type=int, default=10, help="ìƒì„±í•  ì´ë¯¸ì§€ ìˆ˜")
    parser.add_argument("--batch_size", type=int, default=4)
    parser.add_argument("--resolution", type=int, default=512)
    # ì¤‘ìš”: í•™ìŠµ ë¡œê·¸ì— ì°í˜”ë˜ 'ê¶Œì¥ Scaling Factor' ê°’ì„ ì—¬ê¸°ì— ë„£ìœ¼ì„¸ìš”.
    parser.add_argument("--scale_factor", type=float, default=1.0, help="Latent Scaling Factor (í•™ìŠµ ë¡œê·¸ ì°¸ê³ )")
    parser.add_argument("--gpu", type=int, default=0)
    
    args = parser.parse_args()
    generate_masks(args)