import os
import argparse
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
from tqdm import tqdm
import numpy as np

# í‰ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬
import lpips
from torchmetrics.image import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure, FrechetInceptionDistance, LearnedPerceptualImagePatchSimilarity
from torchmetrics.classification import MulticlassJaccardIndex, MulticlassAccuracy

# ------------------------------
# 1. ì‚¬ìš©ì ì •ì˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ (ìˆ˜ì • í•„ìš”)
# ------------------------------
class SegmentationEvaluator(nn.Module):
    def __init__(self, num_classes=2):
        super().__init__()
        # TODO: ì—¬ê¸°ì— ì‹¤ì œë¡œ í•™ìŠµëœ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ì„ ë¡œë“œí•˜ì„¸ìš”.
        # ì˜ˆ: self.model = torch.load("my_best_segmentation_model.pth")
        # ì•„ë˜ëŠ” ì˜ˆì‹œìš© ë”ë¯¸ ëª¨ë¸ (ResNet50-DeepLabV3 ë“±)
        from torchvision.models.segmentation import deeplabv3_resnet50
        self.model = deeplabv3_resnet50(num_classes=num_classes) 
        # self.model.load_state_dict(...) # ê°€ì¤‘ì¹˜ ë¡œë“œ í•„ìˆ˜!
        
    def forward(self, x):
        # ëª¨ë¸ì— ë”°ë¼ ì¶œë ¥ í˜•ì‹ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ (dict['out'] ë˜ëŠ” tensor)
        out = self.model(x)
        if isinstance(out, dict):
            out = out['out']
        return out

# ------------------------------
# 2. ë°ì´í„°ì…‹ ì •ì˜
# ------------------------------
class EvaluationDataset(Dataset):
    def __init__(self, real_dir, fake_dir, mask_dir=None, size=512):
        self.real_dir = real_dir
        self.fake_dir = fake_dir
        self.mask_dir = mask_dir
        self.size = size
        
        # íŒŒì¼ëª… ë§¤ì¹­ (í™•ì¥ì ë¬´ì‹œ)
        self.filenames = sorted([f for f in os.listdir(fake_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
        
        self.transform = transforms.Compose([
            transforms.Resize((size, size)),
            transforms.ToTensor(),
            # NormalizeëŠ” ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¦„. ì—¬ê¸°ì„  [0, 1] ìœ ì§€í•˜ê±°ë‚˜ í•„ìš”ì‹œ ì¶”ê°€
        ])
        
        # ë§ˆìŠ¤í¬ëŠ” ìµœê·¼ì ‘ ì´ì›ƒ(Nearest)ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆí•´ì•¼ ê°’ì´ ì•ˆ ê¹¨ì§
        self.mask_transform = transforms.Compose([
            transforms.Resize((size, size), interpolation=transforms.InterpolationMode.NEAREST),
            transforms.ToTensor() # ê°’ì€ ê·¸ëŒ€ë¡œ 0, 1 ìœ ì§€
        ])

    def __len__(self):
        return len(self.filenames)

    def __getitem__(self, idx):
        fname = self.filenames[idx]
        
        # 1. Fake Image (Generated)
        fake = Image.open(os.path.join(self.fake_dir, fname)).convert("RGB")
        fake = self.transform(fake)
        
        # 2. Real Image (Ground Truth)
        real_path = os.path.join(self.real_dir, fname)
        if os.path.exists(real_path):
            real = Image.open(real_path).convert("RGB")
            real = self.transform(real)
        else:
            real = torch.zeros_like(fake) # ì—†ì„ ê²½ìš° ëŒ€ë¹„

        # 3. Mask (Ground Truth for Segmentation)
        mask = torch.tensor([])
        if self.mask_dir:
            mask_path = os.path.join(self.mask_dir, fname)
            if os.path.exists(mask_path):
                mask_img = Image.open(mask_path).convert("L") # Grayscale
                mask = self.mask_transform(mask_img)
                # [0, 1] ë²”ìœ„ì˜ í…ì„œë¥¼ ì •ìˆ˜ í´ë˜ìŠ¤ ì¸ë±ìŠ¤(0, 1)ë¡œ ë³€í™˜
                mask = (mask * 255).long().squeeze(0)
                mask = (mask > 128).long() # ì´ì§„ ë§ˆìŠ¤í¬ ê°€ì •
            
        return {"fake": fake, "real": real, "mask": mask}

# ------------------------------
# 3. ë©”ì¸ í‰ê°€ í•¨ìˆ˜
# ------------------------------
def evaluate(args):
    device = torch.device(f"cuda:{args.gpu}" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ í‰ê°€ ì‹œì‘ (Device: {device})")
    
    # --- Metrics ì´ˆê¸°í™” ---
    psnr = PeakSignalNoiseRatio().to(device)
    ssim = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)
    lpips_metric = LearnedPerceptualImagePatchSimilarity(net_type='alex').to(device)
    fid = FrechetInceptionDistance(feature=2048).to(device)
    
    # Segmentation Metrics (Optional)
    use_seg = args.mask_dir is not None
    if use_seg:
        print("â„¹ï¸ Segmentation Accuracy í‰ê°€ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.")
        seg_model = SegmentationEvaluator(num_classes=2).to(device)
        seg_model.eval()
        iou = MulticlassJaccardIndex(num_classes=2).to(device)
        acc = MulticlassAccuracy(num_classes=2).to(device)
    
    # --- DataLoader ---
    dataset = EvaluationDataset(args.real_dir, args.fake_dir, args.mask_dir, args.size)
    dataloader = DataLoader(dataset, batch_size=args.batch_size, num_workers=4)
    
    # --- Evaluation Loop ---
    psnr_scores, ssim_scores, lpips_scores = [], [], []
    
    print("ğŸ“Š ë°ì´í„° ì²˜ë¦¬ ë° Metric ê³„ì‚° ì¤‘...")
    for batch in tqdm(dataloader):
        fake_imgs = batch['fake'].to(device) # [B, 3, H, W]
        real_imgs = batch['real'].to(device)
        
        # 1. Image Quality Metrics (Pairwise)
        # ê°’ì„ [0, 1] ë²”ìœ„ë¡œ í´ë¨í•‘ (ì•ˆì „ì„ ìœ„í•´)
        fake_imgs = torch.clamp(fake_imgs, 0, 1)
        real_imgs = torch.clamp(real_imgs, 0, 1)

        psnr_scores.append(psnr(fake_imgs, real_imgs).item())
        ssim_scores.append(ssim(fake_imgs, real_imgs).item())
        lpips_scores.append(lpips_metric(fake_imgs * 2 - 1, real_imgs * 2 - 1).item()) # LPIPSëŠ” [-1, 1] ê¶Œì¥
        
        # 2. FID Update (Distribution)
        # FIDëŠ” uint8 [0, 255] ì…ë ¥ì„ ê¸°ëŒ€í•¨
        fake_uint8 = (fake_imgs * 255).byte()
        real_uint8 = (real_imgs * 255).byte()
        
        fid.update(real_uint8, real=True)
        fid.update(fake_uint8, real=False)
        
        # 3. Segmentation Accuracy
        if use_seg:
            target_masks = batch['mask'].to(device) # [B, H, W]
            if target_masks.numel() > 0:
                with torch.no_grad():
                    # Fake Image -> Seg Model -> Pred Mask
                    seg_out = seg_model(fake_imgs) # [B, 2, H, W]
                    pred_masks = torch.argmax(seg_out, dim=1)
                    
                    iou.update(pred_masks, target_masks)
                    acc.update(pred_masks, target_masks)

    # --- ê²°ê³¼ ì§‘ê³„ ---
    final_fid = fid.compute().item()
    avg_psnr = np.mean(psnr_scores)
    avg_ssim = np.mean(ssim_scores)
    avg_lpips = np.mean(lpips_scores)
    
    print("\n" + "="*40)
    print(f"ğŸ† ìµœì¢… í‰ê°€ ê²°ê³¼ ({args.name})")
    print("="*40)
    print(f"1. [í’ˆì§ˆ]   FID   (â†“): {final_fid:.4f}  (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)")
    print(f"2. [ì§€ê°]   LPIPS (â†“): {avg_lpips:.4f}  (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)")
    print(f"3. [êµ¬ì¡°]   SSIM  (â†‘): {avg_ssim:.4f}   (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ)")
    print(f"4. [í”½ì…€]   PSNR  (â†‘): {avg_psnr:.2f} dB")
    
    if use_seg:
        final_miou = iou.compute().item()
        final_acc = acc.compute().item()
        print("-" * 40)
        print(f"5. [ì˜ë¯¸]   mIoU  (â†‘): {final_miou:.4f}")
        print(f"6. [ì˜ë¯¸]   Acc   (â†‘): {final_acc:.4f}")
    print("="*40)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--name", type=str, default="Model Evaluation", help="í‰ê°€ ì´ë¦„")
    parser.add_argument("--real_dir", type=str, required=True, help="Ground Truth ì´ë¯¸ì§€ í´ë”")
    parser.add_argument("--fake_dir", type=str, required=True, help="ìƒì„±ëœ ì´ë¯¸ì§€ í´ë”")
    parser.add_argument("--mask_dir", type=str, default=None, help="Segmentation í‰ê°€ìš© ë§ˆìŠ¤í¬ í´ë” (ì„ íƒ)")
    parser.add_argument("--batch_size", type=int, default=8)
    parser.add_argument("--size", type=int, default=512)
    parser.add_argument("--gpu", type=int, default=0)
    
    args = parser.parse_args()
    evaluate(args)