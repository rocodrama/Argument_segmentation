import os
import argparse
import numpy as np
from tqdm import tqdm
from PIL import Image
from pathlib import Path

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from torchvision.utils import save_image

# í‰ê°€ ë©”íŠ¸ë¦­
import lpips
from torchmetrics.functional import peak_signal_noise_ratio as psnr
from torchmetrics.functional import structural_similarity_index_measure as ssim

from pix2pix_model import UnetGenerator, NLayerDiscriminator, weights_init_normal

# ------------------------------
# 1. Dataset
# ------------------------------
class PairedDataset(Dataset):
    def __init__(self, root_dir, split='train', size=512):
        self.root_dir = Path(root_dir) / split
        self.size = size
        
        self.mask_dir = self.root_dir / 'masks'
        self.image_dir = self.root_dir / 'images'
        self.filenames = sorted([f.name for f in self.mask_dir.iterdir() if f.suffix in ['.jpg', '.png', '.jpeg']])
        
        # 512x512 Resize
        self.transform = transforms.Compose([
            transforms.Resize((size, size)), 
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])

    def __len__(self):
        return len(self.filenames)

    def __getitem__(self, idx):
        fname = self.filenames[idx]
        mask = Image.open(self.mask_dir / fname).convert('RGB')
        image = Image.open(self.image_dir / fname).convert('RGB')
        return {'A': self.transform(mask), 'B': self.transform(image), 'path': fname}

# ------------------------------
# 2. Training Script
# ------------------------------
def train(args):
    device = torch.device(f"cuda:{args.gpu}" if torch.cuda.is_available() else "cpu")
    os.makedirs(args.output_dir, exist_ok=True)
    sample_dir = os.path.join(args.output_dir, 'samples')
    os.makedirs(sample_dir, exist_ok=True)

    train_dataset = PairedDataset(args.data_dir, split='train', size=args.size)
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4)
    
    val_dataset = PairedDataset(args.data_dir, split='val', size=args.size)
    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=1)

    print(f"ğŸš€ Pix2Pix (512x512) í•™ìŠµ ì‹œì‘")
    print(f" - Train: {len(train_dataset)}ì¥, Val: {len(val_dataset)}ì¥")
    print(f" - Batch Size: {args.batch_size} (Accum: {args.gradient_accumulation_steps}) -> Effective: {args.batch_size * args.gradient_accumulation_steps}")

    # --- ëª¨ë¸ ì´ˆê¸°í™” ---
    netG = UnetGenerator(input_nc=3, output_nc=3, num_downs=9, ngf=64).to(device)
    netD = NLayerDiscriminator(input_nc=6, ndf=64, n_layers=3).to(device)

    netG.apply(weights_init_normal)
    netD.apply(weights_init_normal)

    criterionGAN = nn.BCEWithLogitsLoss()
    criterionL1 = nn.L1Loss()
    loss_fn_lpips = lpips.LPIPS(net='alex').to(device)

    optimizer_G = torch.optim.Adam(netG.parameters(), lr=args.lr, betas=(0.5, 0.999))
    optimizer_D = torch.optim.Adam(netD.parameters(), lr=args.lr, betas=(0.5, 0.999))

    # [ì¶”ê°€] GradScaler ì´ˆê¸°í™” (Mixed Precision)
    scaler = torch.cuda.amp.GradScaler()

    for epoch in range(args.epochs):
        netG.train()
        netD.train()
        
        tqdm_bar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{args.epochs}")
        
        # Epoch ì‹œì‘ ì „ Grad ì´ˆê¸°í™”
        optimizer_G.zero_grad()
        optimizer_D.zero_grad()

        for i, batch in enumerate(tqdm_bar):
            real_A = batch['A'].to(device) # Mask
            real_B = batch['B'].to(device) # Real

            # ==========================
            # 1. Update Discriminator
            # ==========================
            # [ìˆ˜ì •] Autocast ì ìš©
            with torch.cuda.amp.autocast():
                fake_B = netG(real_A)

                # Real Loss
                real_AB = torch.cat((real_A, real_B), 1)
                pred_real = netD(real_AB)
                loss_D_real = criterionGAN(pred_real, torch.ones_like(pred_real))

                # Fake Loss
                fake_AB = torch.cat((real_A, fake_B.detach()), 1)
                pred_fake = netD(fake_AB)
                loss_D_fake = criterionGAN(pred_fake, torch.zeros_like(pred_fake))

                loss_D = (loss_D_real + loss_D_fake) * 0.5
                
                # [ì¶”ê°€] Gradient Accumulationì„ ìœ„í•´ Loss ë‚˜ëˆ„ê¸°
                loss_D = loss_D / args.gradient_accumulation_steps

            # [ìˆ˜ì •] Scaled Backward
            scaler.scale(loss_D).backward()

            # ==========================
            # 2. Update Generator
            # ==========================
            # [ìˆ˜ì •] Autocast ì ìš©
            with torch.cuda.amp.autocast():
                # D ì—…ë°ì´íŠ¸ ì‹œ fake_Bë¥¼ detachí–ˆìœ¼ë¯€ë¡œ G ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´ ê·¸ë˜í”„ ìœ ì§€ í•„ìš”í•˜ê±°ë‚˜ ë‹¤ì‹œ ê³„ì‚°
                # ë³´í†µ Pix2Pix êµ¬í˜„ì—ì„œëŠ” fake_Bë¥¼ ë‹¤ì‹œ catí•´ì„œ ì‚¬ìš© (ì—¬ê¸°ì„  ìœ„ì—ì„œ ê³„ì‚°í•œ fake_B ì¬ì‚¬ìš©)
                
                fake_AB = torch.cat((real_A, fake_B), 1)
                pred_fake = netD(fake_AB)
                loss_G_GAN = criterionGAN(pred_fake, torch.ones_like(pred_fake))
                loss_G_L1 = criterionL1(fake_B, real_B) * args.lambda_L1

                loss_G = loss_G_GAN + loss_G_L1
                
                # [ì¶”ê°€] Loss ë‚˜ëˆ„ê¸°
                loss_G = loss_G / args.gradient_accumulation_steps

            # [ìˆ˜ì •] Scaled Backward
            scaler.scale(loss_G).backward()

            # ==========================
            # 3. Step & Zero Grad (Accumulation Check)
            # ==========================
            if (i + 1) % args.gradient_accumulation_steps == 0:
                # D ì—…ë°ì´íŠ¸
                scaler.step(optimizer_D)
                # G ì—…ë°ì´íŠ¸
                scaler.step(optimizer_G)
                
                scaler.update()
                
                optimizer_D.zero_grad()
                optimizer_G.zero_grad()

            # ë¡œê¹…ìš© (ë‚˜ëˆ´ë˜ ê°’ì„ ë‹¤ì‹œ ê³±í•´ì„œ í‘œì‹œ)
            tqdm_bar.set_postfix({
                'D': loss_D.item() * args.gradient_accumulation_steps, 
                'G': loss_G.item() * args.gradient_accumulation_steps
            })

        # --- Validation ---
        if (epoch + 1) % args.val_interval == 0:
            evaluate(netG, val_loader, loss_fn_lpips, device, sample_dir, epoch)
            torch.save(netG.state_dict(), os.path.join(args.output_dir, f'netG_epoch_{epoch+1}.pth'))

@torch.no_grad()
def evaluate(netG, val_loader, loss_fn_lpips, device, sample_dir, epoch):
    netG.eval()
    total_psnr, total_ssim, total_lpips = 0.0, 0.0, 0.0
    
    for i, batch in enumerate(val_loader):
        real_A = batch['A'].to(device)
        real_B = batch['B'].to(device)
        
        # Validationë„ Autocast ì ìš©
        with torch.cuda.amp.autocast():
            fake_B = netG(real_A)
            
            # Metric ê³„ì‚°ì„ ìœ„í•´ float32ë¡œ ë³€í™˜ ë° Range [0, 1] ì¡°ì •
            fake_B_norm = (fake_B.float() + 1) / 2
            real_B_norm = (real_B.float() + 1) / 2
            
            total_psnr += psnr(fake_B_norm, real_B_norm, data_range=1.0).item()
            total_ssim += ssim(fake_B_norm, real_B_norm, data_range=1.0).item()
            # LPIPSëŠ” ë‚´ë¶€ì ìœ¼ë¡œ ì²˜ë¦¬ê°€ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë‚˜ ë³´í†µ float32 ì…ë ¥ì„ ì„ í˜¸
            total_lpips += loss_fn_lpips(fake_B.float(), real_B.float()).item()
        
        if i == 0:
            vis = torch.cat((real_A, real_B, fake_B), dim=3)
            vis = (vis + 1) / 2.0
            # ì €ì¥ ì‹œì—ëŠ” float32ë¡œ í™•ì‹¤í•˜ê²Œ ë³€í™˜
            save_image(vis.float(), os.path.join(sample_dir, f'val_epoch_{epoch+1}.png'))
            
    n = len(val_loader)
    print(f"\nğŸ“Š Epoch {epoch+1} | PSNR: {total_psnr/n:.2f} | SSIM: {total_ssim/n:.4f} | LPIPS: {total_lpips/n:.4f}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--data_dir', type=str, required=True)
    parser.add_argument('--output_dir', type=str, default='results_pix2pix_512')
    parser.add_argument('--epochs', type=int, default=200)
    
    # ë°°ì¹˜ ì‚¬ì´ì¦ˆ ë° Accumulation ì„¤ì •
    parser.add_argument('--batch_size', type=int, default=4, help="ë¬¼ë¦¬ì  ë°°ì¹˜ ì‚¬ì´ì¦ˆ") 
    parser.add_argument('--gradient_accumulation_steps', type=int, default=4, help="ë…¼ë¦¬ì  ë°°ì¹˜ ëˆ„ì  íšŸìˆ˜")
    
    parser.add_argument('--lr', type=float, default=0.0002)
    parser.add_argument('--size', type=int, default=512, help="ì´ë¯¸ì§€ í•´ìƒë„")
    parser.add_argument('--lambda_L1', type=float, default=100.0)
    parser.add_argument('--val_interval', type=int, default=5)
    parser.add_argument('--gpu', type=int, default=0)
    
    args = parser.parse_args()
    train(args)